{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb69448-d66b-4c5c-86f0-59d6de0ac604",
   "metadata": {},
   "source": [
    "### Jackknife & Bootstrap Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9cf22-86c2-46e5-86b2-db4b03d02bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.physik.uni-leipzig.de/~spitzner/publications/Spitzner_bootstrap.pdf\n",
    "@everywhere function MyJackknife(x, fun, W = 1)\n",
    "    P = size(x, 1) # number of arguments to fun\n",
    "    \n",
    "    N = length(x[1])\n",
    "    M = ceil(Int64, N/W) # number of blocks (ceil accounts for shorter blocks if W doesn't factor N)\n",
    "    \n",
    "    blocks = [[x[p][1+(m-1)*W : min(m*W,N)] for m=1:M] for p=1:P] # M x P x W nested vectors    \n",
    "    samples = [[vcat(blocks[p][1:end .!= n]...) for p=1:P] for n=1:M] # M x P x W*(M-1) nested vectors\n",
    "    \n",
    "    fmavg = [fun(samples[n]...) for n in 1:M] # run function on all resamplings\n",
    "    \n",
    "    favg1 = mean(fmavg) # biased jackknife estimator\n",
    "    favg = (N*fun(x...) - (N-M)*favg1)/M # UNbiased jackknife estimator\n",
    "    ferr = sqrt(sum((fmavg .- favg1).^2)*(M-1)/M) # error in estimator\n",
    "\n",
    "    return favg, ferr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9de6c9-fd05-4590-becf-65abb1010e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.physik.uni-leipzig.de/~spitzner/publications/Spitzner_bootstrap.pdf\n",
    "@everywhere function MyBootstrap(x, fun, W, Nbps = M) \n",
    "    P = size(x, 1) # number of arguments to fun\n",
    "    \n",
    "    N = length(x[1])\n",
    "    M = ceil(Int64, N/W) # number of blocks (ceil accounts for shorter blocks if W doesn't factor N)\n",
    "    \n",
    "    blocks = [[x[p][1+(m-1)*W : min(m*W,N)] for m=1:M] for p=1:P] # M x P x W nested vectors\n",
    "    rands = [rand(1:M, M) for n=1:Nbps] # have to precompute these so they're the same for all variables p\n",
    "    samples = [[vcat(blocks[p][rands[n]]...) for p=1:P] for n=1:Nbps] # Nbps x P x W*M nested vectors\n",
    "    \n",
    "    fmavg = [fun(samples[n]...) for n in 1:Nbps] # construct Nbps randomly-chosen length-M resamplings and average each one\n",
    "    \n",
    "    favg = mean(fmavg) # biased estimator (bias hard to estimate and usually small => typically ignored)\n",
    "    ferr = sqrt(sum((fmavg .- favg).^2)/(Nbps-1)) # error in estimator\n",
    "\n",
    "    return favg, ferr\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93096f5d-6253-49c8-b341-6f80925c5b47",
   "metadata": {},
   "source": [
    "### Override Bootstrap because it's currently broken!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333b0f9-49a1-4b71-965e-b3a4f5835969",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function MyBootstrap(x, fun, W, Nbps = -1)\n",
    "    return fun(x...), 0 # MyJackknife(x, fun, W) # \n",
    "end\n",
    "# BOOTSTRAP DISABLED - CURRENTLY FAILS FOR LOW TEMPERATURES??? PERHAPS B/C AUTOCORRELATION EFFECTS LARGE??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a614181-7da0-4140-8a3f-c4cb955574aa",
   "metadata": {},
   "source": [
    "### Autocorrelation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2791c-3738-47d7-821d-5a80ebb6b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function MyAutocor(y, normalise=true) # shamelessly stolen from the StatsBase package - had to b/c of package issues on the TCM network\n",
    "    D = size(y, 1)\n",
    "    T = size(y, 2)\n",
    "    \n",
    "    lags = range(0,T-1)\n",
    "    \n",
    "    r = zeros(D, length(lags))\n",
    "    for d in 1:D\n",
    "        for (t, lag) in enumerate(lags)  # for each lag value\n",
    "            r[d,t] = sum(y[d,1:T-lag] .* y[d,1+lag:T])\n",
    "            r[d,t] /= T - lag\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if normalise\n",
    "        r ./= r[:,1]\n",
    "    end\n",
    "    \n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f91e3-be83-460f-b85a-456aa93e4163",
   "metadata": {},
   "source": [
    "### Integrated autocorrelation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6c56a-b531-4213-b1c7-c52cad9df7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function IntAutocorrTime(x)\n",
    "    y = MyAutocor(hcat(x...)')\n",
    "    y = y[:,2:end] # cut out τ=0 term\n",
    "    y .*= ones(size(y)) .- repeat(collect(range(1,size(y,2))), 1, size(y,1))'./size(y,2)\n",
    "    return ceil(Int64, 1 + 2 * maximum(sum(y, dims=2))) # exclude τ=0 term\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed798f2-207d-49f2-baea-5cc035f5980e",
   "metadata": {},
   "source": [
    "### Useful alternative functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf6ecf-c03c-49bf-a6f6-165c9cf31dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere Var(x) = (length(x)>1) ? var(x) : 0.0"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Julia (6 threads) 1.8.2",
   "language": "julia",
   "name": "julia-(6-threads)-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
